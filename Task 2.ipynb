{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4354de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------\n",
    "# TASK 2 (ML eng. only)\n",
    "# --------\n",
    "\n",
    "# Imagine the digits in the test set of the MNIST dataset\n",
    "# (http://yann.lecun.com/exdb/mnist/) got cut in half vertically and shuffled\n",
    "# around. Implement a way to restore the original test set from the two halves,\n",
    "# whilst maximising the overall matching accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6c68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import idx2numpy\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e6c948",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "My approach to this task can be summarized as follows:\n",
    "1. Create a convolutional neural network for recognition of unaltered MNIST written digits.\n",
    "2. Splitting the image into halves.\n",
    "3. Create another network for generating right halves from left halves.\n",
    "4. Splitting and shuffling the test set halves (halves and their labels remain in the same order in resulting data, so that we can check how the accuracy of matching and predictions).\n",
    "5. Re-matching halves and predicting number from the joined images using the original model from point 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270f2da",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "(please first unzip all of the archives downloaded from the Yann LeCun's website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49054369",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = idx2numpy.convert_from_file(\"mnist/train-images-idx3-ubyte\").astype(np.float32)\n",
    "y_train = idx2numpy.convert_from_file(\"mnist/train-labels-idx1-ubyte\").astype(np.float32)\n",
    "X_test = idx2numpy.convert_from_file(\"mnist/t10k-images-idx3-ubyte\").astype(np.float32)\n",
    "y_test = idx2numpy.convert_from_file(\"mnist/t10k-labels-idx1-ubyte\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124df7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make categorical y arrays for the purposes of training\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fae04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f815522",
   "metadata": {},
   "source": [
    "Imports for constructing neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a988fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Reshape, Conv2DTranspose, Cropping2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2bfb1",
   "metadata": {},
   "source": [
    "### Build a model for digit recognition\n",
    "\n",
    "A simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27d0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(50, (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Conv2D(50, (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "    model.add(MaxPool2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be93799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1a7d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 50)        500       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 50)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 50)        22550     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1250)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1250)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                12510     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,560\n",
      "Trainable params: 35,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058f4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop callback for training\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37ad95",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb87f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 15:38:44.381253: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1734 - accuracy: 0.9470 - val_loss: 0.0484 - val_accuracy: 0.9861\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0610 - accuracy: 0.9817 - val_loss: 0.0383 - val_accuracy: 0.9869\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.0328 - val_accuracy: 0.9894\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.0264 - val_accuracy: 0.9907\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.0288 - val_accuracy: 0.9906\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0305 - val_accuracy: 0.9901\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0305 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154519ee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.reshape(-1,28,28,1), y_train_cat, epochs=30, \n",
    "          validation_data=[X_test.reshape(-1,28,28,1), y_test_cat],\n",
    "         callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14f792",
   "metadata": {},
   "source": [
    "Saving the model so that we don't have to train it every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4810416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"task2-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495402ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_number(img):\n",
    "    \"\"\"\n",
    "    Predict number from image (full).\n",
    "    \"\"\"\n",
    "    return model.predict(img.reshape(-1,28,28,1)).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa78f5b",
   "metadata": {},
   "source": [
    "### Separation and matching of halves in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35db63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into halves\n",
    "X_train_left = X_train[:,:,:14]\n",
    "X_train_right = X_train[:,:,14:]\n",
    "X_test_left = X_test[:,:,:14]\n",
    "X_test_right = X_test[:,:,14:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c2f1a",
   "metadata": {},
   "source": [
    "Creating a model for generating right half from left half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f2e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_half_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(60, (3, 3), input_shape=(28,14,1), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(MaxPool2D((2, 2), padding=\"same\"))\n",
    "    model.add(Conv2D(60, (3, 3), input_shape=(28,14,1), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(MaxPool2D((2, 2), padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(25, activation=\"relu\"))\n",
    "    model.add(Dense(1680, activation=\"relu\"))\n",
    "    model.add(Reshape((7,4,60)))\n",
    "    model.add(Conv2DTranspose(60, (3, 3), strides=2, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(Conv2DTranspose(60, (3, 3), strides=2, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\"))\n",
    "    model.add(Cropping2D(cropping=(0, 1)))\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a93ecfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_to_right = create_half_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025ed87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0419 - accuracy: 0.7820\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0317 - accuracy: 0.7858\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0299 - accuracy: 0.7868\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0289 - accuracy: 0.7872\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0283 - accuracy: 0.7876\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0278 - accuracy: 0.7878\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0274 - accuracy: 0.7880\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0270 - accuracy: 0.7882\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0267 - accuracy: 0.7883\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0264 - accuracy: 0.7885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15c83f610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_to_right.fit(X_train_left.reshape(-1,28,14,1), X_train_right.reshape(-1,28,14,1), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e513e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_to_right.save(\"task2-l2r.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5b0b6",
   "metadata": {},
   "source": [
    "Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed2d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "337ddcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1627f9460>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test_left[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df5810c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(half):\n",
    "    \"\"\"\n",
    "    Generate right half from left half.\n",
    "    \"\"\"\n",
    "    input_array = half.reshape(-1,28,14,1)\n",
    "    return left_to_right.predict(input_array).reshape(28,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c3e8e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1629cb700>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predict(X_test_left[sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1695f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x162a32670>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test_right[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e2030",
   "metadata": {},
   "source": [
    "Visually, it does a decent job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d6d7bb",
   "metadata": {},
   "source": [
    "Now we merge and shuffle the halves into a new set with 10000 * 2 elements.\n",
    "\n",
    "Labels remain ordered the same way as halves so that we can check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6236a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_x_test = np.concatenate([X_test_left.copy(), X_test_right.copy()], 0)\n",
    "shuffled_y_test = np.concatenate([y_test.copy(), y_test.copy()], 0)\n",
    "indices = list(range(20000))\n",
    "shuffle(indices)\n",
    "shuffled_x_test = shuffled_x_test[indices]\n",
    "shuffled_y_test = shuffled_y_test[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72c868",
   "metadata": {},
   "source": [
    "And here I create classes for re-matching the halves.\n",
    "\n",
    "In my approach, I do not remove the matched right halves from the pool. This means that some new images will have identical right halves, while some right halves will not be used. I found that this leads to better overall agreement between original labels and new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63e46b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(half):\n",
    "    \"\"\"\n",
    "    Generate right half from left half.\n",
    "    \"\"\"\n",
    "    input_array = half.reshape(-1,28,14,1)\n",
    "    return left_to_right.predict(input_array).reshape(28,14)\n",
    "\n",
    "\n",
    "def check_im_match(pred, test):\n",
    "    \"\"\"\n",
    "    Evaluate the extent to which two image halves match (simple RMSE).\n",
    "    \"\"\"\n",
    "    dist = test - (pred / test.max())\n",
    "    return np.sqrt((dist**2).sum(-1).sum(-1))\n",
    "\n",
    "\n",
    "def which_half(half):\n",
    "    \"\"\"\n",
    "    Function to determine whether the given half is left or right.\n",
    "    Density of pixel brightness on each side of a given half-array is evaluated.\n",
    "    \"\"\"\n",
    "    left_side = half[:,:3].sum()\n",
    "    right_side = half[:,-3:].sum()\n",
    "    if left_side > right_side:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"left\"\n",
    "\n",
    "\n",
    "class SeparateTestHalves:\n",
    "    \"\"\"\n",
    "    Class for separating the shuffled data into left and right halves.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.left_x, self.right_x, self.left_y, self.right_y = self.get_halves()\n",
    "    \n",
    "    def get_halves(self):\n",
    "        halves_filter = np.array([which_half(half) for half in self.x])\n",
    "        leftind = np.argwhere(halves_filter == \"left\")\n",
    "        rightind = np.argwhere(halves_filter == \"right\")\n",
    "        left_x = self.x[leftind].reshape(-1,28,14)\n",
    "        right_x = self.x[rightind].reshape(-1,28,14)\n",
    "        left_y = self.y[leftind].reshape(-1)\n",
    "        right_y = self.y[rightind].reshape(-1)\n",
    "        return left_x, right_x, left_y, right_y\n",
    "\n",
    "\n",
    "class MatchTestHalves(SeparateTestHalves):\n",
    "    \"\"\"\n",
    "    Extension of the separating class, with match method for joining the halves\n",
    "    and evaluating accuracy of joining halves and of predictions from joined images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def match(self):\n",
    "        \"\"\"\n",
    "        Returns a list of tuples like so:\n",
    "        (merged img, left half label, right half label, new predicted label)\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        for n in range(self.left_x.shape[0]):\n",
    "            left = self.left_x[n]\n",
    "            prediction = predict(left)\n",
    "            scores = check_im_match(prediction, self.right_x)\n",
    "            match_ind = np.argwhere(scores == scores.min())\n",
    "            joined_img = np.concatenate([left, self.right_x[match_ind].reshape(28,14)],1)\n",
    "            left_label = self.left_y[n]\n",
    "            right_label = self.right_y[match_ind].sum() # sum is here to extract the scalar\n",
    "            prediction = predict_number(joined_img)\n",
    "            matches.append((joined_img, left_label, right_label, prediction))\n",
    "        \n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a20dcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "halves = MatchTestHalves(shuffled_x_test, shuffled_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81d3420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_imgs = halves.match()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7618231",
   "metadata": {},
   "source": [
    "This took 8 minutes on my machine (2020 MacBook Pro M1), which is certainly not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b47e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = matched_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "715a7d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b09cd30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75e729",
   "metadata": {},
   "source": [
    "#### Original test set accuracy from the model trained at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01894676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test_predictions = model.predict(X_test.reshape(-1,28,28,1)).argmax(1)\n",
    "(original_test_predictions == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e557dbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(original_test_predictions == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c37e3",
   "metadata": {},
   "source": [
    "#### Agreeement between labels of left and right halves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da966fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halves_label_match = np.array([img[1] == img[2] for img in matched_imgs])\n",
    "halves_label_match.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9133d",
   "metadata": {},
   "source": [
    "#### Agreement between left side label and prediction from re-joined image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d959bcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_match = np.array([img[1] == img[3] for img in matched_imgs])\n",
    "pred_label_match.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2df11a",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Overall the test set is recreated, although not quite accurately. I think the match between labels of left and right sides is less important than the agreement between original left side labels and the labels predicted from the regenerated image. That is because ultimately we are interested in the recovery of the test set.\n",
    "Room for improvement:\n",
    "- finding a better method for evaluating similarity between predicted and matches halves;\n",
    "- better scaling of the matching process - 7 minutes is, I think, quite a long time for processing 10000 datapoints, although the splitting into halves is a destructive process, so recovery of the information is not that easy;\n",
    "- a better model for recognition of entire digits can certainly be constructed, but I decided not to focus on that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3abac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
